{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3xppaCzJnuT"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from tensorflow.keras.layers import AveragePooling2D, Input, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation\n",
        "from tensorflow.keras.layers import AlphaDropout\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRtm3nIbJnuU"
      },
      "outputs": [],
      "source": [
        "# Add the swish function to Keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.activations import softplus, tanh, sigmoid, softplus, elu, selu, relu, softsign, hard_sigmoid\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.backend import sin\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "from tensorflow.keras.layers import ThresholdedReLU\n",
        "\n",
        "\n",
        "#learnable param\n",
        "# beta=tf.Variable(0.1)\n",
        "# def swish(x):\n",
        "#     return x*tf.math.sigmoid(beta*x)\n",
        "# get_custom_objects().update({'Swish':Activation(swish)})\n",
        "\n",
        "from tensorflow.keras.activations import sigmoid, relu, tanh, softplus, selu, elu, softsign\n",
        "def SoftClipping_Swish(x):\n",
        "    return tf.maximum(0.0, swish(x))\n",
        "get_custom_objects().update({'SC Swish':Activation(SoftClipping_Swish)})\n",
        "\n",
        "def swish(x):\n",
        "    return x*sigmoid(x)\n",
        "get_custom_objects().update({'Swish':Activation(swish)})\n",
        "\n",
        "act_func = ['sigmoid', 'tanh', 'relu', 'Swish', 'SC Swish']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQYReOohJnuV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cd96fc4-8b43-41a4-800a-327a0c30d102"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n",
            "170508288/170498071 [==============================] - 11s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "# Load the CIFAR10 data.\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiUJlaB_JnuW",
        "outputId": "b5a6eb96-3bcb-45b5-89c3-9cceb7077b66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "y_train shape: (50000, 1)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Training parameters\n",
        "# batch_size = 32  # orig paper trained all networks with batch_size=128\n",
        "batch_size = 128\n",
        "epochs = 50\n",
        "data_augmentation = False\n",
        "num_classes = 10\n",
        "\n",
        "# Subtracting pixel mean improves accuracy\n",
        "subtract_pixel_mean = True\n",
        "\n",
        "n = 3\n",
        "# Model version\n",
        "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
        "version = 1\n",
        "\n",
        "# Computed depth from supplied model parameter n\n",
        "if version == 1:\n",
        "    depth = n * 6 + 2\n",
        "elif version == 2:\n",
        "    depth = n * 9 + 2\n",
        "\n",
        "# Model name, depth and version\n",
        "model_type = 'ResNet%dv%d' % (depth, version)\n",
        "\n",
        "def preprocess_cifar10(x_train, y_train, x_test, y_test):\n",
        "    # Input image dimensions.\n",
        "    input_shape = x_train.shape[1:]\n",
        "\n",
        "    # Normalize data.\n",
        "    x_train = x_train.astype('float32') / 255\n",
        "    x_test = x_test.astype('float32') / 255\n",
        "\n",
        "    # If subtract pixel mean is enabled\n",
        "    if subtract_pixel_mean:\n",
        "        x_train_mean = np.mean(x_train, axis=0)\n",
        "        x_train -= x_train_mean\n",
        "        x_test -= x_train_mean\n",
        "\n",
        "    print('x_train shape:', x_train.shape)\n",
        "    print(x_train.shape[0], 'train samples')\n",
        "    print(x_test.shape[0], 'test samples')\n",
        "    print('y_train shape:', y_train.shape)\n",
        "\n",
        "    # Convert class vectors to binary class matrices.\n",
        "    y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "    y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "    \n",
        "    return x_train, y_train, x_test, y_test, input_shape\n",
        "    \n",
        "x_train, y_train, x_test, y_test, input_shape = preprocess_cifar10(x_train, y_train, x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 1e-5\n",
        "    if epoch > 180:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 120:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 80:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr\n"
      ],
      "metadata": {
        "id": "fMYv9V8Up2XO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNsjcL3YJnuY"
      },
      "outputs": [],
      "source": [
        "for activation in act_func:\n",
        "    def resnet_layer(inputs,\n",
        "                     num_filters=16,\n",
        "                     kernel_size=3,\n",
        "                     strides=1,\n",
        "                     activation=activation,\n",
        "                     batch_normalization=True,\n",
        "                     conv_first=True):\n",
        "        \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "        # Arguments\n",
        "            inputs (tensor): input tensor from input image or previous layer\n",
        "            num_filters (int): Conv2D number of filters\n",
        "            kernel_size (int): Conv2D square kernel dimensions\n",
        "            strides (int): Conv2D square stride dimensions\n",
        "            activation (string): activation name\n",
        "            batch_normalization (bool): whether to include batch normalization\n",
        "            conv_first (bool): conv-bn-activation (True) or\n",
        "                bn-activation-conv (False)\n",
        "\n",
        "        # Returns\n",
        "            x (tensor): tensor as input to the next layer\n",
        "        \"\"\"\n",
        "        conv = Conv2D(num_filters,\n",
        "                      kernel_size=kernel_size,\n",
        "                      strides=strides,\n",
        "                      padding='same',\n",
        "                      kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(1e-4))\n",
        "\n",
        "        x = inputs\n",
        "        if conv_first:\n",
        "            x = conv(x)\n",
        "            if batch_normalization:\n",
        "                x = BatchNormalization()(x)\n",
        "            if activation is not None:\n",
        "                x = Activation(activation)(x)\n",
        "        else:\n",
        "            if batch_normalization:\n",
        "                x = BatchNormalization()(x)\n",
        "            if activation is not None:\n",
        "                x = Activation(activation)(x)\n",
        "            x = conv(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GD7vEfPTJnuZ"
      },
      "outputs": [],
      "source": [
        "def resnet_v1(activation,input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 1 Model builder [a]\n",
        "\n",
        "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
        "    Last ReLU is after the shortcut connection.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filters is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same number of filters.\n",
        "    Features maps sizes:\n",
        "    stage 0: 32x32, 16\n",
        "    stage 1: 16x16, 32\n",
        "    stage 2:  8x8,  64\n",
        "    The Number of parameters is approx the same as Table 6 of [a]:\n",
        "    ResNet20 0.27M\n",
        "    ResNet32 0.46M\n",
        "    ResNet44 0.66M\n",
        "    ResNet56 0.85M\n",
        "    ResNet110 1.7M\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 6 != 0:\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
        "    # Start model definition.\n",
        "    num_filters = 16\n",
        "    num_res_blocks = int((depth - 2) / 6)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs)\n",
        "    # Instantiate the stack of residual units\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                strides = 2  # downsample\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters,\n",
        "                             strides=strides)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters,\n",
        "                             activation=None)\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x =tf.keras.layers.add([x, y])\n",
        "            x = Activation(activation)(x)\n",
        "        num_filters *= 2\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWD9beVpJnua",
        "outputId": "29eff32e-28be-4071-9a51-7f9fb10dfb3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate:  1e-05\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 32, 32, 16)   448         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 32, 32, 16)  64          ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 32, 32, 16)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 32, 32, 16)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 32, 32, 16)   0           ['activation_2[0][0]',           \n",
            "                                                                  'batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 32, 32, 16)   0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 32, 32, 16)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 32, 32, 16)   0           ['activation_4[0][0]',           \n",
            "                                                                  'batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 32, 32, 16)   0           ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 32, 32, 16)   0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 32, 32, 16)   0           ['activation_6[0][0]',           \n",
            "                                                                  'batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 32, 32, 16)   0           ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 16, 16, 32)   4640        ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 16, 16, 32)  128         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 16, 16, 32)   0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 16, 16, 32)   9248        ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 16, 16, 32)   544         ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 16, 16, 32)  128         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 16, 16, 32)   0           ['conv2d_9[0][0]',               \n",
            "                                                                  'batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 16, 16, 32)   0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 16, 16, 32)  128         ['conv2d_10[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 16, 16, 32)  128         ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 16, 16, 32)   0           ['activation_10[0][0]',          \n",
            "                                                                  'batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 16, 16, 32)   0           ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 16, 16, 32)  128         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 16, 16, 32)  128         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 16, 16, 32)   0           ['activation_12[0][0]',          \n",
            "                                                                  'batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 16, 16, 32)   0           ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 8, 8, 64)     18496       ['activation_14[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 8, 8, 64)    256         ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 8, 8, 64)     2112        ['activation_14[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 8, 8, 64)    256         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 8, 8, 64)     0           ['conv2d_16[0][0]',              \n",
            "                                                                  'batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 8, 8, 64)     0           ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 8, 8, 64)    256         ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_17[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 8, 8, 64)    256         ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 8, 8, 64)     0           ['activation_16[0][0]',          \n",
            "                                                                  'batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 8, 8, 64)     0           ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 8, 8, 64)    256         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_19[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 8, 8, 64)    256         ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 8, 8, 64)     0           ['activation_18[0][0]',          \n",
            "                                                                  'batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 8, 8, 64)     0           ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 1, 1, 64)    0           ['activation_20[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 64)           0           ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 10)           650         ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 274,442\n",
            "Trainable params: 273,066\n",
            "Non-trainable params: 1,376\n",
            "__________________________________________________________________________________________________\n",
            "ResNet20v1\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
        "\n",
        "model = resnet_v1(activation=activation, input_shape=input_shape, depth=depth)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(learning_rate=lr_schedule(0)),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "print(model_type)\n",
        "\n",
        "# Prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "earlyStopping = EarlyStopping(monitor='val_acc', \n",
        "                              min_delta=0, \n",
        "                              patience=20, \n",
        "                              verbose=0, mode='auto', \n",
        "                              baseline=None, \n",
        "                              restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=20,\n",
        "                               min_lr=0.5e-6)\n",
        "tb=TensorBoard(log_dir='./logs', \n",
        "               histogram_freq=0, \n",
        "               write_graph=True, \n",
        "               write_grads=False, \n",
        "               write_images=True, \n",
        "               embeddings_freq=0, \n",
        "               embeddings_layer_names=None,\n",
        "               embeddings_metadata=None, embeddings_data=None, update_freq='epoch')\n",
        "\n",
        "\n",
        "callbacks = [earlyStopping, checkpoint, lr_reducer, lr_scheduler, tb]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ctb23uxKI5vO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYAfiw-XJnub",
        "outputId": "60986b2b-294b-48dc-a8ea-ef9307313c82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with -->sigmoid<-- activation function\n",
            "\n",
            "Not using data augmentation.\n",
            "Learning rate:  1e-05\n",
            "Epoch 1/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.0975 - accuracy: 0.1199WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "391/391 [==============================] - 743s 2s/step - loss: 3.0975 - accuracy: 0.1199 - val_loss: 2.6060 - val_accuracy: 0.1065 - lr: 1.0000e-05\n",
            "Learning rate:  1e-05\n",
            "Epoch 2/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.5298 - accuracy: 0.1435WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "391/391 [==============================] - 750s 2s/step - loss: 2.5298 - accuracy: 0.1435 - val_loss: 2.4633 - val_accuracy: 0.1483 - lr: 1.0000e-05\n",
            "Learning rate:  1e-05\n",
            "Epoch 3/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.4008 - accuracy: 0.1636WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "391/391 [==============================] - 746s 2s/step - loss: 2.4008 - accuracy: 0.1636 - val_loss: 2.3556 - val_accuracy: 0.1738 - lr: 1.0000e-05\n",
            "Learning rate:  1e-05\n",
            "Epoch 4/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.3201 - accuracy: 0.1863WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "391/391 [==============================] - 738s 2s/step - loss: 2.3201 - accuracy: 0.1863 - val_loss: 2.2818 - val_accuracy: 0.2074 - lr: 1.0000e-05\n",
            "Learning rate:  1e-05\n",
            "Epoch 5/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.2443 - accuracy: 0.2303WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "391/391 [==============================] - 751s 2s/step - loss: 2.2443 - accuracy: 0.2303 - val_loss: 2.2083 - val_accuracy: 0.2460 - lr: 1.0000e-05\n",
            "Learning rate:  1e-05\n",
            "Epoch 6/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.1669 - accuracy: 0.2628WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "391/391 [==============================] - 744s 2s/step - loss: 2.1669 - accuracy: 0.2628 - val_loss: 2.1270 - val_accuracy: 0.2718 - lr: 1.0000e-05\n",
            "Learning rate:  1e-05\n",
            "Epoch 7/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.0895 - accuracy: 0.2887WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "391/391 [==============================] - 742s 2s/step - loss: 2.0895 - accuracy: 0.2887 - val_loss: 2.0495 - val_accuracy: 0.3019 - lr: 1.0000e-05\n",
            "Learning rate:  1e-05\n",
            "Epoch 8/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.0210 - accuracy: 0.3123WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "391/391 [==============================] - 740s 2s/step - loss: 2.0210 - accuracy: 0.3123 - val_loss: 1.9844 - val_accuracy: 0.3246 - lr: 1.0000e-05\n",
            "Learning rate:  1e-05\n",
            "Epoch 9/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.9680 - accuracy: 0.3309WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "391/391 [==============================] - 727s 2s/step - loss: 1.9680 - accuracy: 0.3309 - val_loss: 1.9288 - val_accuracy: 0.3484 - lr: 1.0000e-05\n",
            "Learning rate:  1e-05\n",
            "Epoch 10/50\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.9222 - accuracy: 0.3491WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "391/391 [==============================] - 742s 2s/step - loss: 1.9222 - accuracy: 0.3491 - val_loss: 1.8863 - val_accuracy: 0.3672 - lr: 1.0000e-05\n",
            "Learning rate:  1e-05\n",
            "Epoch 11/50\n",
            " 69/391 [====>.........................] - ETA: 9:41 - loss: 1.9062 - accuracy: 0.3534"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-7e26d18137b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m                   \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                   \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                   callbacks=callbacks)\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "result = []\n",
        "final_acc = []\n",
        "final_loss = []\n",
        "name=[]\n",
        "for activation in act_func:\n",
        "    print('\\nTraining with -->{0}<-- activation function\\n'.format(activation))\n",
        "    # model = model(activation=activation,\n",
        "    #                           input_shape=input_shape,\n",
        "    #                           depth=depth)\n",
        "    # Run training, with or without data augmentation.\n",
        "    if not data_augmentation:\n",
        "        print('Not using data augmentation.')\n",
        "        history = model.fit(x_train, y_train,\n",
        "                  batch_size=batch_size,\n",
        "                  epochs=epochs,\n",
        "                  validation_data=(x_test, y_test),\n",
        "                  shuffle=True,\n",
        "                  callbacks=callbacks)\n",
        "        \n",
        "        result.append(history)\n",
        "        final_acc.append(history.history['val_accuracy'][-1])\n",
        "        final_loss.append(history.history['val_loss'][-1])\n",
        "        name.append(activation)\n",
        "        \n",
        "        print('{} \\n val loss: {}, val acc: {}\\n'.format(activation,history.history['val_loss'][-1], history.history['val_accuracy'][-1]))\n",
        "\n",
        "    else:\n",
        "        print('Using real-time data augmentation.')\n",
        "        # This will do preprocessing and realtime data augmentation:\n",
        "        # datagen = ImageDataGenerator(\n",
        "        #     # set input mean to 0 over the dataset\n",
        "        #     featurewise_center=False,\n",
        "        #     # set each sample mean to 0\n",
        "        #     samplewise_center=False,\n",
        "        #     # divide inputs by std of dataset\n",
        "        #     featurewise_std_normalization=False,\n",
        "        #     # divide each input by its std\n",
        "        #     samplewise_std_normalization=False,\n",
        "        #     # apply ZCA whitening\n",
        "        #     zca_whitening=False,\n",
        "        #     # epsilon for ZCA whitening\n",
        "        #     zca_epsilon=1e-06,\n",
        "        #     # randomly rotate images in the range (deg 0 to 180)\n",
        "        #     rotation_range=0,\n",
        "        #     # randomly shift images horizontally\n",
        "        #     width_shift_range=0.1,\n",
        "        #     # randomly shift images vertically\n",
        "        #     height_shift_range=0.1,\n",
        "        #     # set range for random shear\n",
        "        #     shear_range=0.,\n",
        "        #     # set range for random zoom\n",
        "        #     zoom_range=0.,\n",
        "        #     # set range for random channel shifts\n",
        "        #     channel_shift_range=0.,\n",
        "        #     # set mode for filling points outside the input boundaries\n",
        "        #     fill_mode='nearest',\n",
        "        #     # value used for fill_mode = \"constant\"\n",
        "        #     cval=0.,\n",
        "        #     # randomly flip images\n",
        "        #     horizontal_flip=True,\n",
        "        #     # randomly flip images\n",
        "        #     vertical_flip=False,\n",
        "        #     # set rescaling factor (applied before any other transformation)\n",
        "        #     rescale=None,\n",
        "        #     # set function that will be applied on each input\n",
        "        #     preprocessing_function=None,\n",
        "        #     # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        #     data_format=None,\n",
        "        #     # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        #     validation_split=0.0)\n",
        "\n",
        "        # # Compute quantities required for featurewise normalization\n",
        "        # # (std, mean, and principal components if ZCA whitening is applied).\n",
        "        # history = datagen.fit(x_train)\n",
        "\n",
        "        # # Fit the model on the batches generated by datagen.flow().\n",
        "        # history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "        #                     validation_data=(x_test, y_test),\n",
        "        #                     epochs=epochs, verbose=1, workers=4,\n",
        "        #                     callbacks=callbacks)\n",
        "        # result.append(history)\n",
        "        # final_acc.append(history.history['val_accuracy'][-1])\n",
        "        # final_loss.append(history.history['val_loss'][-1])\n",
        "        # name.append(activation)\n",
        "        \n",
        "        # print('{} \\n val loss: {}, val acc: {}\\n'.format(activation,history.history['val_loss'][-1], history.history['val_accuracy'][-1]))\n",
        "\n",
        "print(result)\n",
        "\n",
        "# i=0\n",
        "\n",
        "\n",
        "# a=0\n",
        "# while(i<len(act_func)):\n",
        "#     dict={name[i]: {final_acc[i], final_loss[i]}}\n",
        "    \n",
        "#     print(dict)\n",
        "#     if i>0 and final_acc[i]>final_acc[i-1]:\n",
        "#         a=final_acc[i]\n",
        "#         nume=name[i]\n",
        "#     i+=1\n",
        "# print('Best acc made by function {} with acc of {}'.format(nume,a))\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEfKmqnPJnuc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.set_theme()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "new_act_arr = act_func[0:]\n",
        "new_results = result[0:]\n",
        "\n",
        "def plot_act_func_results(results, activation_functions = []):\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.style.use('seaborn-poster')\n",
        "    \n",
        "    # Plot validation accuracy values\n",
        "    for act_func in results:\n",
        "        plt.plot(act_func.history['val_accuracy'])\n",
        "        \n",
        "    plt.title('Model accuracy')\n",
        "    plt.ylabel('Test Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(activation_functions)\n",
        "    plt.show()\n",
        "\n",
        "    # Plot validation loss values\n",
        "    plt.figure(figsize=(10,10))\n",
        "    \n",
        "    for act_func in results:\n",
        "        plt.plot(act_func.history['val_loss'])\n",
        "        \n",
        "    plt.title('Model loss')\n",
        "    plt.ylabel('Test Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(activation_functions)\n",
        "    plt.show()\n",
        "\n",
        "plot_act_func_results(new_results, new_act_arr)"
      ],
      "metadata": {
        "id": "a3_A8Q4EqRdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OeTijjYsJnue"
      },
      "outputs": [],
      "source": [
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "# sns.set_theme(style=\"darkgrid\")\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def tanh(x):\n",
        "    return (np.exp(x)-np.exp(-x)) / (np.exp(x) + np.exp(-x))\n",
        "\n",
        "def der_hyperb(x):\n",
        "    return 1 - ((np.exp(x)-np.exp(-x)) / (np.exp(x) + np.exp(-x)))**2\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data which will go through activations\n",
        "x = np.linspace(-2,2,200)\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.style.use('seaborn-poster')\n",
        "\n",
        "\n",
        "\n",
        "plt.plot(x, sigmoid(x), label=\"Sigmoid\")\n",
        "plt.plot(x, tanh(x), label=\"tanh\")\n",
        "plt.plot(x, relu(x), label=\"ReLU\")\n",
        "plt.plot(x, swish(x), label=\"Swish\")\n",
        "plt.plot(x, SoftClipping_Swish(x), label=\"SC Swish\", ls='-.')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y = f(x)')\n",
        "plt.axhline(lw=1, c='black')\n",
        "plt.axvline(lw=1, c='black')\n",
        "plt.grid(alpha=0.4, ls='-.')\n",
        "# plt.box(on=None)\n",
        "plt.title(\"Activation functions\", fontsize = 16)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HSSEACSmBB1Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Resnet20_Cifar10_saci2021_dis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}